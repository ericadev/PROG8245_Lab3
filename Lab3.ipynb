{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea69ea5b",
   "metadata": {},
   "source": [
    "# PROG8245-25S-Sec1 Lab 3\n",
    "Erica Holden, 5490685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fbe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas psycopg2 seaborn matplotlib faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31328a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lab3:\n",
    "    def __init__(self):\n",
    "        self.conn_str = \"postgresql://neondb_owner:npg_WSpuZFCo8K6n@ep-lucky-block-a5dsr90p-pooler.us-east-2.aws.neon.tech/neondb?sslmode=require\"\n",
    "    \n",
    "    def generateEmployeeData(): \n",
    "        \"\"\" Generate employee data with random names, positions, start dates, and salaries \"\"\"\n",
    "        fake = Faker()\n",
    "        positions = ['Software Engineer', 'Data Analyst', 'DevOps Engineer', 'ML Engineer', 'QA Engineer', 'Backend Developer', 'Frontend Developer', 'Cloud Architect', 'SysAdmin', 'Data Scientist']\n",
    "        for i in range(50):\n",
    "            name = fake.name().replace(\"'\", \"''\") # Escape single quotes for SQL\n",
    "            position = random.choice(positions)\n",
    "            start=datetime.date(2015, 1, 1)\n",
    "            end=datetime.date(2024, 6, 1)\n",
    "            start_date = fake.date_between(start_date=start, end_date=end)\n",
    "            salary = random.randint(60000, 200000)\n",
    "            print(f\"INSERT INTO employees (name, position, start_date, salary) VALUES('{name}', '{position}', '{start_date}', {salary});\")\n",
    "\n",
    "    def generateProjectData(self):\n",
    "        \"\"\" Generate project data with random department IDs, start and end dates, and employee IDs \"\"\"\n",
    "        fake = Faker()\n",
    "        department_ids = [1, 2, 3, 4, 5]\n",
    "        for i in range(20):\n",
    "            department_id = int(random.choice(department_ids))\n",
    "            start=datetime.date(2015, 1, 1)\n",
    "            end=datetime.date(2017, 6, 1)\n",
    "            start_date = fake.date_between(start_date=start, end_date=end)\n",
    "            start=datetime.date(2017, 12, 1)\n",
    "            end=datetime.date(2020, 6, 1)\n",
    "            end_date = fake.date_between(start_date=start, end_date=end)\n",
    "            employee_id = random.randint(1, 50)\n",
    "            print(f\"INSERT INTO projects (department_id, start_date, end_date, employee_id) VALUES('{department_id}', '{start_date}', '{end_date}', {employee_id});\")\n",
    "        \n",
    "        \n",
    "    def loadEmployeeDataToDataframe(self):\n",
    "        \"\"\" Load employee data from the database into a dataframe \"\"\"\n",
    "        conn = psycopg2.connect(self.conn_str)\n",
    "        df = pd.read_sql_query(\"SELECT * FROM employees;\", conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def loadProjectDataToDataframe(self):\n",
    "        \"\"\" Load project data from the database into a dataframe \"\"\"\n",
    "        conn = psycopg2.connect(self.conn_str)\n",
    "        df = pd.read_sql_query(\"SELECT * FROM projects;\", conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def removeNullValues(self, df):\n",
    "        \"\"\" Remove rows with null values \"\"\"\n",
    "        df = df.dropna()\n",
    "        return df\n",
    "    \n",
    "    def mergeAndCorrectData(self, employee_df, project_df):\n",
    "        \"\"\" Merge and return employee & project dataframes, ensuring that the employee's start date is before or equal to the project's start date \"\"\"\n",
    "        merged_df = pd.merge(employee_df, project_df, left_on='employee_id', right_on='employee_id', how='inner')\n",
    "        merged_df['employee_start_date'] = pd.to_datetime(merged_df['start_date_x'])\n",
    "        merged_df['project_start_date'] = pd.to_datetime(merged_df['start_date_y'])\n",
    "        # Keep only rows where employee's start_date is before or equal to project's start_date\n",
    "        merged_df = merged_df[merged_df['employee_start_date'] <= merged_df['project_start_date']]\n",
    "        # Remove unnecessary columns, start_date_x is now employee_start_date, and start_date_y is now project_start_date\n",
    "        merged_df = merged_df.drop(columns=['start_date_x', 'start_date_y'])\n",
    "        return merged_df\n",
    "\n",
    "\n",
    "    def plotFirstVisualization(self, df):\n",
    "        \"\"\" Plot the average salary by position and start year \"\"\"\n",
    "        df_modified = df.copy()\n",
    "        df_modified['start_year'] = pd.to_datetime(df['start_date']).dt.year\n",
    "        df_modified.groupby(['position', 'start_year']).mean('salary')\n",
    "        sns.barplot(data=df_modified, x='position', y='salary', hue='start_year')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title('Average Salary by Position and Start Year')\n",
    "        plt.show()\n",
    "\n",
    "    def plotSecondVisualization(self, df):\n",
    "        \"\"\" Plot the distribution of projects per employee \"\"\"\n",
    "        emp_counts = df['employee_id'].value_counts()\n",
    "        sns.histplot(emp_counts, bins=10)\n",
    "        plt.xlabel('Number of Projects per Employee')\n",
    "        plt.title('Distribution of Projects per Employee')\n",
    "        plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab3 = Lab3()\n",
    "employeeDf = lab3.loadEmployeeDataToDataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7f6f6",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "The employee data was generated in a script which is demonstrated above as the generateEmployeeData method of the Lab3 class. The departments table was created manually - 5 departments named Project Alpha, Project Beta, Project Delta, Project Gamma, and Project Epsilon. The projects table joins the employees and departments and the data was generated using the method generateProjectData of the Lab3 class.\n",
    "\n",
    "## 2. Data Cleaning\n",
    "\n",
    "The removeNullValues method of the Lab3 class above will drop null values from the dataframe.\n",
    "\n",
    "## 3. Data Transformation & Feature Engineering\n",
    "\n",
    "The plotData method of the Lab3 class above will modify the dataframe by adding a column for start_year, which is extracted from the start_date column's year.\n",
    "\n",
    "## 4. Scaling\n",
    "\n",
    "No scaling was appropriate.\n",
    "\n",
    "## 5. Visualization 1: Average Salary by Position and Start Year\n",
    "\n",
    "Please see the following cell for plotting the average salary by position and start year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dcde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab3.plotFirstVisualization(employeeDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e6ec8",
   "metadata": {},
   "source": [
    "## 6. Visualization 2: Distribution of Projects Per Employee\n",
    "\n",
    "Please see the following cell for plotting number of projects per employee. \n",
    "\n",
    "A new pair of tables were created - departments and projects. As above, departments was manually created to contain 5 departments. The projects table was generated using the generateProjectData method of the Lab3 class. The data for employees and projects was merged, with code removing rows where the employee start date was after the project start date. There are only three projects that weren't filtered out. Then the data is plotted below - one employee had one project, and another employee had 2 projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectDf = lab3.loadProjectDataToDataframe()\n",
    "mergedEmployeesAndProjectsDf = lab3.mergeAndCorrectData(employeeDf, projectDf)\n",
    "\n",
    "lab3.plotSecondVisualization(mergedEmployeesAndProjectsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9a279",
   "metadata": {},
   "source": [
    "## 7. Insights and Conclusions\n",
    "\n",
    "The year 2024 seems to have shown the highest salaries. The Backend Developers and QA Engineers appear to have high salaries in general. \n",
    "\n",
    "Because the data was generated randomly for the projects by employee, it wasn't ideal. The generated start dates of the projects were too often before the start date of the employee, which is invalid data, and was removed. This meant only 3 employees had \"realistic\" project data, which made for a not-very-exciting visualization of number of projects per employee. In a real-world situation this would likely not occur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
